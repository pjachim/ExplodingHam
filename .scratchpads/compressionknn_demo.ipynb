{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c71687",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explodingham.models.compression_learning import CompressionKNN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475fa38",
   "metadata": {},
   "source": [
    "## Example 1: Simple Binary Classification with Default Parameters\n",
    "\n",
    "Let's start with a simple example classifying short vs. repeated text patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5b3017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "  1. 'abcdefgh' -> class 0\n",
      "  2. 'ijklmnop' -> class 0\n",
      "  3. 'qrstuvwx' -> class 0\n",
      "  4. 'ababababab' -> class 1\n",
      "  5. 'cdcdcdcdcd' -> class 1\n",
      "  6. 'efefefefefef' -> class 1\n",
      "\n",
      "Test set:\n",
      "  1. 'xyzabc'\n",
      "  2. 'xyxyxyxy'\n"
     ]
    }
   ],
   "source": [
    "# Training data: short random text (class 0) vs. repetitive text (class 1)\n",
    "X_train = [\n",
    "    \"abcdefgh\",           # class 0: random\n",
    "    \"ijklmnop\",           # class 0: random\n",
    "    \"qrstuvwx\",           # class 0: random\n",
    "    \"ababababab\",         # class 1: repetitive\n",
    "    \"cdcdcdcdcd\",         # class 1: repetitive\n",
    "    \"efefefefefef\",       # class 1: repetitive\n",
    "]\n",
    "\n",
    "y_train = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "# Test data\n",
    "X_test = [\n",
    "    \"xyzabc\",             # Should be class 0 (random)\n",
    "    \"xyxyxyxy\",           # Should be class 1 (repetitive)\n",
    "]\n",
    "\n",
    "print(\"Training set:\")\n",
    "for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "    print(f\"  {i+1}. '{x}' -> class {y}\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "for i, x in enumerate(X_test):\n",
    "    print(f\"  {i+1}. '{x}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879f6afd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Fit and predict\u001b[39;00m\n\u001b[32m      5\u001b[39m clf_default.fit(X_train, y_train)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m predictions = \u001b[43mclf_default\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredictions with default parameters (k=5):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, pred) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_test, predictions)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\models\\compression_learning\\knn.py:81\u001b[39m, in \u001b[36mCompressionKNN.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Predict the class labels for the provided data.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \u001b[33;03m        Predicted class labels.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_labels_or_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\models\\compression_learning\\knn.py:101\u001b[39m, in \u001b[36mCompressionKNN._predict_labels_or_predict_proba\u001b[39m\u001b[34m(self, X, return_probs)\u001b[39m\n\u001b[32m     98\u001b[39m labels = []\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[32m    100\u001b[39m     distances = [\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mncd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m train_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stored_X\n\u001b[32m    102\u001b[39m     ]\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# Get top n_neighbors from self.stored_y based on distances\u001b[39;00m\n\u001b[32m    105\u001b[39m     neighbor_indices = np.argsort(distances)[:\u001b[38;5;28mself\u001b[39m.n_neighbors]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\utils\\distance_metrics\\ncd.py:170\u001b[39m, in \u001b[36mNormalizedCompressionDistance.ncd\u001b[39m\u001b[34m(self, x, y)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mncd\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m, y: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    Compute the Normalized Compression Distance between two strings.\u001b[39;00m\n\u001b[32m    114\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    168\u001b[39m \u001b[33;03m    typically negligible.\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     Cx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     Cy = \u001b[38;5;28mself\u001b[39m.compress_size(y)\n\u001b[32m    172\u001b[39m     Cxy = \u001b[38;5;28mself\u001b[39m.compress_size(x + y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\utils\\distance_metrics\\ncd.py:109\u001b[39m, in \u001b[36mNormalizedCompressionDistance.compress_size\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompress_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     83\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    Get the compressed size of the given data.\u001b[39;00m\n\u001b[32m     85\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m    True\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\gzip.py:608\u001b[39m, in \u001b[36mcompress\u001b[39m\u001b[34m(data, compresslevel, mtime)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compress data in one shot and return the compressed string.\u001b[39;00m\n\u001b[32m    602\u001b[39m \n\u001b[32m    603\u001b[39m \u001b[33;03mcompresslevel sets the compression level in range of 0-9.\u001b[39;00m\n\u001b[32m    604\u001b[39m \u001b[33;03mmtime can be used to set the modification time. The modification time is\u001b[39;00m\n\u001b[32m    605\u001b[39m \u001b[33;03mset to the current time by default.\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    607\u001b[39m \u001b[38;5;66;03m# Wbits=31 automatically includes a gzip header and trailer.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m gzip_data = \u001b[43mzlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwbits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m31\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mtime \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    610\u001b[39m     mtime = time.time()\n",
      "\u001b[31mTypeError\u001b[39m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# Create classifier with default parameters (n_neighbors=5, compression='gzip')\n",
    "clf_default = CompressionKNN()\n",
    "\n",
    "# Fit and predict\n",
    "clf_default.fit(X_train, y_train)\n",
    "predictions = clf_default.predict(X_test)\n",
    "\n",
    "print(\"Predictions with default parameters (k=5):\")\n",
    "for i, (x, pred) in enumerate(zip(X_test, predictions)):\n",
    "    print(f\"  '{x}' -> class {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6881af2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get prediction probabilities\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m probabilities = \u001b[43mclf_default\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPrediction probabilities:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, prob) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_test, probabilities)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\models\\compression_learning\\knn.py:95\u001b[39m, in \u001b[36mCompressionKNN.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m     84\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m    Predict class probabilities for the provided data.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     93\u001b[39m \u001b[33;03m        Predicted class probabilities.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_labels_or_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\models\\compression_learning\\knn.py:101\u001b[39m, in \u001b[36mCompressionKNN._predict_labels_or_predict_proba\u001b[39m\u001b[34m(self, X, return_probs)\u001b[39m\n\u001b[32m     98\u001b[39m labels = []\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[32m    100\u001b[39m     distances = [\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mncd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m train_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stored_X\n\u001b[32m    102\u001b[39m     ]\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# Get top n_neighbors from self.stored_y based on distances\u001b[39;00m\n\u001b[32m    105\u001b[39m     neighbor_indices = np.argsort(distances)[:\u001b[38;5;28mself\u001b[39m.n_neighbors]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\utils\\distance_metrics\\ncd.py:170\u001b[39m, in \u001b[36mNormalizedCompressionDistance.ncd\u001b[39m\u001b[34m(self, x, y)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mncd\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m, y: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    Compute the Normalized Compression Distance between two strings.\u001b[39;00m\n\u001b[32m    114\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    168\u001b[39m \u001b[33;03m    typically negligible.\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     Cx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     Cy = \u001b[38;5;28mself\u001b[39m.compress_size(y)\n\u001b[32m    172\u001b[39m     Cxy = \u001b[38;5;28mself\u001b[39m.compress_size(x + y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Computer\\Desktop\\phd_repos\\ExplodingHam\\src\\explodingham\\utils\\distance_metrics\\ncd.py:109\u001b[39m, in \u001b[36mNormalizedCompressionDistance.compress_size\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompress_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     83\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    Get the compressed size of the given data.\u001b[39;00m\n\u001b[32m     85\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m    True\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\gzip.py:608\u001b[39m, in \u001b[36mcompress\u001b[39m\u001b[34m(data, compresslevel, mtime)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compress data in one shot and return the compressed string.\u001b[39;00m\n\u001b[32m    602\u001b[39m \n\u001b[32m    603\u001b[39m \u001b[33;03mcompresslevel sets the compression level in range of 0-9.\u001b[39;00m\n\u001b[32m    604\u001b[39m \u001b[33;03mmtime can be used to set the modification time. The modification time is\u001b[39;00m\n\u001b[32m    605\u001b[39m \u001b[33;03mset to the current time by default.\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    607\u001b[39m \u001b[38;5;66;03m# Wbits=31 automatically includes a gzip header and trailer.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m gzip_data = \u001b[43mzlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwbits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m31\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mtime \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    610\u001b[39m     mtime = time.time()\n",
      "\u001b[31mTypeError\u001b[39m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# Get prediction probabilities\n",
    "probabilities = clf_default.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nPrediction probabilities:\")\n",
    "for i, (x, prob) in enumerate(zip(X_test, probabilities)):\n",
    "    print(f\"  '{x}' -> {prob:.2%} confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445a3d1",
   "metadata": {},
   "source": [
    "## Example 2: Varying k (n_neighbors)\n",
    "\n",
    "Let's see how different values of k affect the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different k values\n",
    "k_values = [1, 3, 5]\n",
    "\n",
    "print(\"Predictions with different k values:\\n\")\n",
    "\n",
    "for k in k_values:\n",
    "    clf = CompressionKNN(n_neighbors=k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    \n",
    "    print(f\"k = {k}:\")\n",
    "    for x, pred, prob in zip(X_test, preds, probs):\n",
    "        print(f\"  '{x}' -> class {pred} ({prob:.2%} confidence)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f5cbf",
   "metadata": {},
   "source": [
    "## Example 3: Language Detection\n",
    "\n",
    "Use CompressionKNN to detect the language of text samples based on character patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1660582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data: English vs Spanish vs French\n",
    "X_lang_train = [\n",
    "    \"the quick brown fox jumps over the lazy dog\",          # English\n",
    "    \"hello world how are you doing today\",                  # English\n",
    "    \"machine learning is a fascinating subject\",            # English\n",
    "    \"el rápido zorro marrón salta sobre el perro perezoso\", # Spanish\n",
    "    \"hola mundo cómo estás haciendo hoy\",                   # Spanish\n",
    "    \"el aprendizaje automático es un tema fascinante\",     # Spanish\n",
    "    \"le renard brun rapide saute par-dessus le chien paresseux\", # French\n",
    "    \"bonjour le monde comment allez-vous aujourd'hui\",     # French\n",
    "    \"l'apprentissage automatique est un sujet fascinant\",  # French\n",
    "]\n",
    "\n",
    "y_lang_train = ['en', 'en', 'en', 'es', 'es', 'es', 'fr', 'fr', 'fr']\n",
    "\n",
    "# Test samples\n",
    "X_lang_test = [\n",
    "    \"this is a test sentence in english\",\n",
    "    \"esta es una oración de prueba en español\",\n",
    "    \"ceci est une phrase de test en français\",\n",
    "]\n",
    "\n",
    "print(\"Language Detection Demo\\n\")\n",
    "print(\"Training on 9 samples (3 per language: English, Spanish, French)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ca45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with k=3 for language detection\n",
    "clf_lang = CompressionKNN(n_neighbors=3)\n",
    "clf_lang.fit(X_lang_train, y_lang_train)\n",
    "\n",
    "# Predict languages\n",
    "lang_predictions = clf_lang.predict(X_lang_test)\n",
    "lang_probabilities = clf_lang.predict_proba(X_lang_test)\n",
    "\n",
    "print(\"Language predictions (k=3):\\n\")\n",
    "for text, pred, prob in zip(X_lang_test, lang_predictions, lang_probabilities):\n",
    "    print(f\"Text: '{text[:50]}...'\")\n",
    "    print(f\"  -> Detected language: {pred} ({prob:.2%} confidence)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6bc5f",
   "metadata": {},
   "source": [
    "## Example 4: Code Snippet Classification\n",
    "\n",
    "Classify code snippets by programming language based on syntax patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a08990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data: Python vs JavaScript\n",
    "X_code_train = [\n",
    "    \"def hello():\\n    print('Hello')\\n    return True\",                    # Python\n",
    "    \"for i in range(10):\\n    result = i * 2\\n    print(result)\",          # Python\n",
    "    \"class MyClass:\\n    def __init__(self):\\n        self.value = 42\",    # Python\n",
    "    \"function hello() {\\n  console.log('Hello');\\n  return true;\\n}\",      # JavaScript\n",
    "    \"for (let i = 0; i < 10; i++) {\\n  let result = i * 2;\\n  console.log(result);\\n}\", # JavaScript\n",
    "    \"class MyClass {\\n  constructor() {\\n    this.value = 42;\\n  }\\n}\",   # JavaScript\n",
    "]\n",
    "\n",
    "y_code_train = ['python', 'python', 'python', 'javascript', 'javascript', 'javascript']\n",
    "\n",
    "X_code_test = [\n",
    "    \"import numpy as np\\ndef process(data):\\n    return np.mean(data)\",\n",
    "    \"const arr = [1, 2, 3];\\nconst doubled = arr.map(x => x * 2);\",\n",
    "]\n",
    "\n",
    "print(\"Code Language Classification Demo\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with different k values\n",
    "for k in [1, 3]:\n",
    "    clf_code = CompressionKNN(n_neighbors=k)\n",
    "    clf_code.fit(X_code_train, y_code_train)\n",
    "    \n",
    "    code_preds = clf_code.predict(X_code_test)\n",
    "    code_probs = clf_code.predict_proba(X_code_test)\n",
    "    \n",
    "    print(f\"\\nPredictions with k={k}:\")\n",
    "    for i, (snippet, pred, prob) in enumerate(zip(X_code_test, code_preds, code_probs)):\n",
    "        print(f\"\\nSnippet {i+1}:\")\n",
    "        print(f\"  {snippet[:60]}...\")\n",
    "        print(f\"  -> Detected: {pred} ({prob:.2%} confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef56341",
   "metadata": {},
   "source": [
    "## Example 5: Multiclass Classification with DNA Sequences\n",
    "\n",
    "Classify DNA sequences into different categories based on their patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21789a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data: Different DNA pattern types\n",
    "X_dna_train = [\n",
    "    \"ATGATGATGATGATG\",      # AT-rich (class 0)\n",
    "    \"ATATATATATATATAT\",     # AT-rich (class 0)\n",
    "    \"ATTAATTAATTAATTA\",     # AT-rich (class 0)\n",
    "    \"GCGCGCGCGCGCGCGC\",     # GC-rich (class 1)\n",
    "    \"GGCCGGCCGGCCGGCC\",     # GC-rich (class 1)\n",
    "    \"CGCGCGCGCGCGCGCG\",     # GC-rich (class 1)\n",
    "    \"ACGTACGTACGTACGT\",     # Mixed (class 2)\n",
    "    \"AGTCAGTCAGTCAGTC\",     # Mixed (class 2)\n",
    "    \"TACGTACGTACGTACG\",     # Mixed (class 2)\n",
    "]\n",
    "\n",
    "y_dna_train = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "class_names = {0: 'AT-rich', 1: 'GC-rich', 2: 'Mixed'}\n",
    "\n",
    "X_dna_test = [\n",
    "    \"ATATGTATGTATGTAT\",     # Should be AT-rich\n",
    "    \"GCGGCGGCGGCGGCGG\",     # Should be GC-rich\n",
    "    \"ACGTCGATCGATCGAT\",     # Should be Mixed\n",
    "]\n",
    "\n",
    "print(\"DNA Sequence Classification Demo\")\n",
    "print(\"Classes: AT-rich (0), GC-rich (1), Mixed (2)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify with k=3\n",
    "clf_dna = CompressionKNN(n_neighbors=3)\n",
    "clf_dna.fit(X_dna_train, y_dna_train)\n",
    "\n",
    "dna_preds = clf_dna.predict(X_dna_test)\n",
    "dna_probs = clf_dna.predict_proba(X_dna_test)\n",
    "\n",
    "print(\"DNA Classification Results (k=3):\\n\")\n",
    "for seq, pred, prob in zip(X_dna_test, dna_preds, dna_probs):\n",
    "    print(f\"Sequence: {seq}\")\n",
    "    print(f\"  -> Class {pred} ({class_names[pred]}) with {prob:.2%} confidence\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc4fe0",
   "metadata": {},
   "source": [
    "## Example 6: Comparison of k=1 vs k=3 vs k=5\n",
    "\n",
    "Let's visualize how the choice of k affects classification consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005bbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test case with some ambiguous samples\n",
    "X_compare_train = [\n",
    "    \"aaaaa\", \"aaaaa\", \"aaaaa\", \"aaaaa\",  # Class A: 4 samples\n",
    "    \"bbbbb\", \"bbbbb\",                     # Class B: 2 samples\n",
    "]\n",
    "\n",
    "y_compare_train = ['A', 'A', 'A', 'A', 'B', 'B']\n",
    "\n",
    "# Ambiguous test sample (closer to B but A has more samples)\n",
    "X_compare_test = [\"bbbba\"]\n",
    "\n",
    "print(\"Comparing different k values on an ambiguous sample\\n\")\n",
    "print(\"Training set: 4 samples of class A ('aaaaa'), 2 samples of class B ('bbbbb')\")\n",
    "print(f\"Test sample: '{X_compare_test[0]}' (mostly B's but with one A)\\n\")\n",
    "\n",
    "for k in [1, 2, 3, 4, 5, 6]:\n",
    "    clf = CompressionKNN(n_neighbors=k)\n",
    "    clf.fit(X_compare_train, y_compare_train)\n",
    "    pred = clf.predict(X_compare_test)[0]\n",
    "    prob = clf.predict_proba(X_compare_test)[0]\n",
    "    \n",
    "    print(f\"k={k}: Predicted class {pred} with {prob:.2%} confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c399278",
   "metadata": {},
   "source": [
    "## Example 7: Custom Encoding\n",
    "\n",
    "The classifier supports custom encoding for string data. By default, it uses UTF-8, but you can specify a different encoding if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df184ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with UTF-8 (default)\n",
    "X_encoding_train = [\n",
    "    \"café\",\n",
    "    \"naïve\", \n",
    "    \"résumé\",\n",
    "    \"hello\",\n",
    "    \"world\",\n",
    "    \"python\"\n",
    "]\n",
    "\n",
    "y_encoding_train = ['french', 'french', 'french', 'english', 'english', 'english']\n",
    "\n",
    "X_encoding_test = [\"jalapeño\", \"computer\"]\n",
    "\n",
    "print(\"Testing with different encodings:\\n\")\n",
    "\n",
    "# UTF-8 encoding (default)\n",
    "clf_utf8 = CompressionKNN(n_neighbors=3, encoding='utf-8')\n",
    "clf_utf8.fit(X_encoding_train, y_encoding_train)\n",
    "preds_utf8 = clf_utf8.predict(X_encoding_test)\n",
    "probs_utf8 = clf_utf8.predict_proba(X_encoding_test)\n",
    "\n",
    "print(\"With UTF-8 encoding (default):\")\n",
    "for text, pred, prob in zip(X_encoding_test, preds_utf8, probs_utf8):\n",
    "    print(f\"  '{text}' -> {pred} ({prob:.2%} confidence)\")\n",
    "\n",
    "# Latin-1 encoding\n",
    "clf_latin1 = CompressionKNN(n_neighbors=3, encoding='latin-1')\n",
    "clf_latin1.fit(X_encoding_train, y_encoding_train)\n",
    "preds_latin1 = clf_latin1.predict(X_encoding_test)\n",
    "probs_latin1 = clf_latin1.predict_proba(X_encoding_test)\n",
    "\n",
    "print(\"\\nWith Latin-1 encoding:\")\n",
    "for text, pred, prob in zip(X_encoding_test, preds_latin1, probs_latin1):\n",
    "    print(f\"  '{text}' -> {pred} ({prob:.2%} confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528c232",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Binary classification** with default parameters\n",
    "2. **Effect of k parameter** on predictions and confidence\n",
    "3. **Language detection** using string labels\n",
    "4. **Code language classification** based on syntax patterns\n",
    "5. **Multiclass classification** with DNA sequences\n",
    "6. **k-value comparison** showing how neighbor count affects results\n",
    "7. **Custom encoding** support for different character encodings\n",
    "\n",
    "Key takeaways:\n",
    "- CompressionKNN works well with text/string data where compression patterns reveal similarity\n",
    "- Strings are automatically converted to bytes using the specified encoding (default: UTF-8)\n",
    "- The classifier can be imported directly: `from explodingham.models.compression_learning import CompressionKNN`\n",
    "- Lower k values (1-3) are more sensitive to local patterns\n",
    "- Higher k values (5+) provide more stable, averaged predictions\n",
    "- The classifier naturally supports both numeric and string labels\n",
    "- Compression-based distance is effective for pattern recognition without feature engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
